{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# INPUT/OUTPUT PATHS\n",
    "# =============================================================================\n",
    "INPUT_CSV_PATH = '/home/smotaali/BGP_Traffic_Generation/results/bgp_updates_analysis_20251208_172321.csv'\n",
    "OUTPUT_DIR = '/home/smotaali/BGP_Traffic_Generation/results/'\n",
    "\n",
    "# =============================================================================\n",
    "# COLUMN NAMES\n",
    "# =============================================================================\n",
    "AS_PATH_COLUMN = 'AS_Path'\n",
    "TIMESTAMP_COLUMN = 'Timestamp'\n",
    "LABEL_COLUMN = 'Label'  # Set to None if no labels\n",
    "\n",
    "# =============================================================================\n",
    "# TIME WINDOW SETTINGS\n",
    "# =============================================================================\n",
    "WINDOW_SIZE = '5min'       # '5min', '1H', '30s', '1D' for time-based; '1000' for count-based\n",
    "WINDOW_TYPE = 'time'       # 'time' or 'count'\n",
    "WINDOW_OVERLAP = 0.0       # 0.0 to 0.9\n",
    "MIN_UPDATES_PER_WINDOW = 10\n",
    "\n",
    "# =============================================================================\n",
    "# LABEL STRATEGY\n",
    "# =============================================================================\n",
    "LABEL_STRATEGY = 'majority'  # 'majority', 'conservative', 'weighted'\n",
    "#ABNORMAL_THRESHOLD = 0.3\n",
    "\n",
    "print(\"Configuration loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction code loaded!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from typing import Dict, List, Tuple, Union, Optional\n",
    "from collections import Counter, defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class ASGraphFeatureExtractor:\n",
    "    \"\"\"Extract graph-based features from AS-level topology.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.graph = None\n",
    "        self.weighted_graph = None\n",
    "        self.as_path_counts = defaultdict(int)\n",
    "        self.df = None\n",
    "        self.label_column = None\n",
    "        self.label_strategy = LABEL_STRATEGY\n",
    "\n",
    "    def parse_as_path(self, as_path_str: str) -> List[int]:\n",
    "        if pd.isna(as_path_str) or not as_path_str:\n",
    "            return []\n",
    "        as_path_str = str(as_path_str).strip()\n",
    "        asns = []\n",
    "        for part in as_path_str.split():\n",
    "            part = part.strip('{}')\n",
    "            if part.isdigit():\n",
    "                asns.append(int(part))\n",
    "        return asns\n",
    "\n",
    "    def extract_all_ases_from_dataframe(self, df: pd.DataFrame, as_path_column: str) -> List[int]:\n",
    "        all_ases = set()\n",
    "        for idx, row in df.iterrows():\n",
    "            if as_path_column not in row:\n",
    "                continue\n",
    "            as_path = self.parse_as_path(row[as_path_column])\n",
    "            all_ases.update(as_path)\n",
    "        return sorted(list(all_ases))\n",
    "\n",
    "    def build_graph_from_dataframe(self, df: pd.DataFrame, as_path_column: str,\n",
    "                                   label_column: Optional[str] = None,\n",
    "                                   verbose: bool = True) -> nx.Graph:\n",
    "        self.graph = nx.Graph()\n",
    "        self.weighted_graph = nx.Graph()\n",
    "        self.as_path_counts = defaultdict(int)\n",
    "        edge_weights = defaultdict(int)\n",
    "        self.df = df\n",
    "        self.label_column = label_column\n",
    "\n",
    "        all_ases = self.extract_all_ases_from_dataframe(df, as_path_column)\n",
    "        for asn in all_ases:\n",
    "            self.graph.add_node(asn)\n",
    "            self.weighted_graph.add_node(asn)\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            if as_path_column not in row:\n",
    "                continue\n",
    "            as_path = self.parse_as_path(row[as_path_column])\n",
    "            if len(as_path) < 1:\n",
    "                continue\n",
    "\n",
    "            for asn in as_path:\n",
    "                if not self.graph.has_node(asn):\n",
    "                    self.graph.add_node(asn)\n",
    "                    self.weighted_graph.add_node(asn)\n",
    "\n",
    "            for i in range(len(as_path) - 1):\n",
    "                source = as_path[i]\n",
    "                target = as_path[i + 1]\n",
    "                if source == target:  # Skip self-loops\n",
    "                    continue\n",
    "                edge = tuple(sorted([source, target]))\n",
    "                edge_weights[edge] += 1\n",
    "                if not self.graph.has_edge(source, target):\n",
    "                    self.graph.add_edge(source, target)\n",
    "\n",
    "            path_tuple = tuple(as_path)\n",
    "            self.as_path_counts[path_tuple] += 1\n",
    "\n",
    "        for (u, v), weight in edge_weights.items():\n",
    "            self.weighted_graph.add_edge(u, v, weight=weight)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Graph constructed: {self.graph.number_of_nodes()} nodes, {self.graph.number_of_edges()} edges\")\n",
    "        return self.graph\n",
    "\n",
    "    def extract_label(self) -> str:\n",
    "        if self.df is None or self.label_column is None:\n",
    "            return 'unknown'\n",
    "        if self.label_column not in self.df.columns:\n",
    "            return 'unknown'\n",
    "        labels = self.df[self.label_column].value_counts()\n",
    "        if labels.empty:\n",
    "            return 'unknown'\n",
    "        if self.label_strategy == 'majority':\n",
    "            return labels.idxmax()\n",
    "        elif self.label_strategy == 'conservative':\n",
    "            if any(label != 'normal' for label in labels.index):\n",
    "                abnormal_labels = [label for label in labels.index if label != 'normal']\n",
    "                return abnormal_labels[0]\n",
    "            return 'normal'\n",
    "        elif self.label_strategy == 'weighted':\n",
    "            total = labels.sum()\n",
    "            abnormal_weight = sum(count for label, count in labels.items() if label != 'normal') / total\n",
    "            if abnormal_weight > ABNORMAL_THRESHOLD:\n",
    "                abnormal_labels = [label for label in labels.index if label != 'normal']\n",
    "                return abnormal_labels[0] if abnormal_labels else 'normal'\n",
    "            return 'normal'\n",
    "        return 'unknown'\n",
    "\n",
    "    def print_graph_summary(self):\n",
    "        if self.graph is None:\n",
    "            print(\"No graph constructed.\")\n",
    "            return\n",
    "        num_nodes = self.graph.number_of_nodes()\n",
    "        num_edges = self.graph.number_of_edges()\n",
    "        max_edges = num_nodes * (num_nodes - 1) / 2\n",
    "        density = num_edges / max_edges if max_edges > 0 else 0\n",
    "        is_connected = nx.is_connected(self.graph)\n",
    "        print(f\"\\nNodes: {num_nodes}, Edges: {num_edges}, Density: {density:.4f}, Connected: {is_connected}\")\n",
    "        if self.label_column and self.df is not None and self.label_column in self.df.columns:\n",
    "            print(f\"Label: {self.extract_label().upper()}\")\n",
    "\n",
    "    def extract_basic_metrics(self) -> Dict:\n",
    "        metrics = {}\n",
    "        if nx.is_connected(self.graph):\n",
    "            G = self.graph\n",
    "        else:\n",
    "            largest_cc = max(nx.connected_components(self.graph), key=len)\n",
    "            G = self.graph.subgraph(largest_cc).copy()\n",
    "        metrics['num_nodes'] = self.graph.number_of_nodes()\n",
    "        metrics['num_edges'] = self.graph.number_of_edges()\n",
    "        try:\n",
    "            metrics['diameter'] = nx.diameter(G)\n",
    "        except:\n",
    "            metrics['diameter'] = -1\n",
    "        triangles = nx.triangles(self.graph)\n",
    "        metrics['num_triangles'] = sum(triangles.values()) // 3\n",
    "        return metrics\n",
    "\n",
    "    def extract_centrality_metrics(self) -> Dict:\n",
    "        metrics = {}\n",
    "        if nx.is_connected(self.graph):\n",
    "            G = self.graph\n",
    "        else:\n",
    "            largest_cc = max(nx.connected_components(self.graph), key=len)\n",
    "            G = self.graph.subgraph(largest_cc).copy()\n",
    "\n",
    "        try:\n",
    "            eig_cent = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "            metrics['eigenvector_centrality_avg'] = np.mean(list(eig_cent.values()))\n",
    "            metrics['eigenvector_centrality_max'] = np.max(list(eig_cent.values()))\n",
    "        except:\n",
    "            metrics['eigenvector_centrality_avg'] = 0.0\n",
    "            metrics['eigenvector_centrality_max'] = 0.0\n",
    "\n",
    "        harm_cent = nx.harmonic_centrality(G)\n",
    "        metrics['harmonic_centrality_avg'] = np.mean(list(harm_cent.values()))\n",
    "        metrics['harmonic_centrality_max'] = np.max(list(harm_cent.values()))\n",
    "\n",
    "        pagerank = nx.pagerank(G)\n",
    "        metrics['pagerank_avg'] = np.mean(list(pagerank.values()))\n",
    "        metrics['pagerank_max'] = np.max(list(pagerank.values()))\n",
    "\n",
    "        deg_cent = nx.degree_centrality(self.graph)\n",
    "        metrics['degree_centrality_avg'] = np.mean(list(deg_cent.values()))\n",
    "        metrics['degree_centrality_max'] = np.max(list(deg_cent.values()))\n",
    "\n",
    "        try:\n",
    "            close_cent = nx.closeness_centrality(G)\n",
    "            metrics['closeness_centrality_avg'] = np.mean(list(close_cent.values()))\n",
    "            metrics['closeness_centrality_max'] = np.max(list(close_cent.values()))\n",
    "        except:\n",
    "            metrics['closeness_centrality_avg'] = 0.0\n",
    "            metrics['closeness_centrality_max'] = 0.0\n",
    "\n",
    "        try:\n",
    "            between_cent = nx.betweenness_centrality(G)\n",
    "            metrics['betweenness_centrality_avg'] = np.mean(list(between_cent.values()))\n",
    "            metrics['betweenness_centrality_max'] = np.max(list(between_cent.values()))\n",
    "        except:\n",
    "            metrics['betweenness_centrality_avg'] = 0.0\n",
    "            metrics['betweenness_centrality_max'] = 0.0\n",
    "\n",
    "        try:\n",
    "            load_cent = nx.load_centrality(G)\n",
    "            metrics['load_centrality_avg'] = np.mean(list(load_cent.values()))\n",
    "            metrics['load_centrality_max'] = np.max(list(load_cent.values()))\n",
    "        except:\n",
    "            metrics['load_centrality_avg'] = 0.0\n",
    "            metrics['load_centrality_max'] = 0.0\n",
    "\n",
    "        try:\n",
    "            ecc = nx.eccentricity(G)\n",
    "            metrics['eccentricity_avg'] = np.mean(list(ecc.values()))\n",
    "            metrics['eccentricity_max'] = np.max(list(ecc.values()))\n",
    "        except:\n",
    "            metrics['eccentricity_avg'] = -1\n",
    "            metrics['eccentricity_max'] = -1\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def extract_connectivity_metrics(self) -> Dict:\n",
    "        metrics = {}\n",
    "        if nx.is_connected(self.graph):\n",
    "            G = self.graph\n",
    "        else:\n",
    "            largest_cc = max(nx.connected_components(self.graph), key=len)\n",
    "            G = self.graph.subgraph(largest_cc).copy()\n",
    "\n",
    "        try:\n",
    "            metrics['algebraic_connectivity'] = nx.algebraic_connectivity(G)\n",
    "        except:\n",
    "            metrics['algebraic_connectivity'] = 0.0\n",
    "\n",
    "        try:\n",
    "            metrics['node_connectivity'] = nx.node_connectivity(G)\n",
    "        except:\n",
    "            metrics['node_connectivity'] = 0\n",
    "\n",
    "        try:\n",
    "            metrics['edge_connectivity'] = nx.edge_connectivity(G)\n",
    "        except:\n",
    "            metrics['edge_connectivity'] = 0\n",
    "\n",
    "        try:\n",
    "            laplacian = nx.laplacian_matrix(G).todense()\n",
    "            eigenvalues = np.linalg.eigvalsh(laplacian)\n",
    "            eigenvalues = eigenvalues[eigenvalues > 1e-10]\n",
    "            if len(eigenvalues) > 0:\n",
    "                metrics['effective_graph_resistance'] = G.number_of_nodes() * np.sum(1.0 / eigenvalues)\n",
    "            else:\n",
    "                metrics['effective_graph_resistance'] = float('inf')\n",
    "        except:\n",
    "            metrics['effective_graph_resistance'] = -1.0\n",
    "\n",
    "        try:\n",
    "            adj_matrix = nx.adjacency_matrix(G).todense()\n",
    "            eigenvalues = np.linalg.eigvalsh(adj_matrix)\n",
    "            metrics['natural_connectivity'] = np.log(np.mean(np.exp(eigenvalues)))\n",
    "        except:\n",
    "            metrics['natural_connectivity'] = 0.0\n",
    "\n",
    "        try:\n",
    "            adj_matrix = nx.adjacency_matrix(G).todense()\n",
    "            eigenvalues = np.real(np.linalg.eigvals(adj_matrix))\n",
    "            metrics['largest_eigenvalue'] = float(np.max(eigenvalues))\n",
    "        except:\n",
    "            metrics['largest_eigenvalue'] = 0.0\n",
    "\n",
    "        try:\n",
    "            norm_lap_eigenvalues = np.real(nx.normalized_laplacian_spectrum(G))\n",
    "            metrics['weighted_spectrum_3'] = float(np.sum(norm_lap_eigenvalues ** 3))\n",
    "            metrics['weighted_spectrum_4'] = float(np.sum(norm_lap_eigenvalues ** 4))\n",
    "        except:\n",
    "            metrics['weighted_spectrum_3'] = 0.0\n",
    "            metrics['weighted_spectrum_4'] = 0.0\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def extract_clustering_metrics(self) -> Dict:\n",
    "        metrics = {}\n",
    "        try:\n",
    "            metrics['assortativity'] = nx.degree_assortativity_coefficient(self.graph)\n",
    "        except:\n",
    "            metrics['assortativity'] = 0.0\n",
    "\n",
    "        try:\n",
    "            square_clust = nx.square_clustering(self.graph)\n",
    "            metrics['square_clustering_avg'] = np.mean(list(square_clust.values()))\n",
    "            metrics['square_clustering_max'] = np.max(list(square_clust.values()))\n",
    "        except:\n",
    "            metrics['square_clustering_avg'] = 0.0\n",
    "            metrics['square_clustering_max'] = 0.0\n",
    "\n",
    "        metrics['avg_clustering'] = nx.average_clustering(self.graph)\n",
    "        return metrics\n",
    "\n",
    "    def extract_robustness_metrics(self) -> Dict:\n",
    "        metrics = {}\n",
    "        components = list(nx.connected_components(self.graph))\n",
    "        metrics['num_components'] = len(components)\n",
    "        metrics['largest_component_size'] = len(max(components, key=len))\n",
    "\n",
    "        bridges = list(nx.bridges(self.graph))\n",
    "        metrics['num_bridges'] = len(bridges)\n",
    "\n",
    "        articulation_points = list(nx.articulation_points(self.graph))\n",
    "        metrics['num_articulation_points'] = len(articulation_points)\n",
    "\n",
    "        try:\n",
    "            if nx.is_connected(self.graph):\n",
    "                laplacian = nx.laplacian_matrix(self.graph).todense()\n",
    "                cofactor = laplacian[1:, 1:]\n",
    "                metrics['num_spanning_trees'] = int(round(np.linalg.det(cofactor)))\n",
    "            else:\n",
    "                metrics['num_spanning_trees'] = 0\n",
    "        except:\n",
    "            metrics['num_spanning_trees'] = -1\n",
    "\n",
    "        try:\n",
    "            degrees = [d for n, d in self.graph.degree()]\n",
    "            k_avg = np.mean(degrees)\n",
    "            k2_avg = np.mean([d**2 for d in degrees])\n",
    "            denominator = k2_avg - k_avg\n",
    "            if denominator > 0:\n",
    "                metrics['percolation_threshold'] = k_avg / denominator\n",
    "            else:\n",
    "                metrics['percolation_threshold'] = 1.0\n",
    "            ratio = k2_avg / k_avg if k_avg > 0 else 1\n",
    "            if ratio > 1:\n",
    "                metrics['percolation_limit'] = 1 - 1 / (ratio - 1)\n",
    "            else:\n",
    "                metrics['percolation_limit'] = 0.0\n",
    "        except:\n",
    "            metrics['percolation_threshold'] = -1.0\n",
    "            metrics['percolation_limit'] = -1.0\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def extract_advanced_metrics(self) -> Dict:\n",
    "        metrics = {}\n",
    "        if nx.is_connected(self.graph):\n",
    "            G = self.graph\n",
    "        else:\n",
    "            largest_cc = max(nx.connected_components(self.graph), key=len)\n",
    "            G = self.graph.subgraph(largest_cc).copy()\n",
    "\n",
    "        try:\n",
    "            degrees = [d for n, d in self.graph.degree()]\n",
    "            degree_counts = Counter(degrees)\n",
    "            total = sum(degree_counts.values())\n",
    "            entropy = -sum((count/total) * np.log(count/total) for count in degree_counts.values())\n",
    "            max_entropy = np.log(len(degree_counts))\n",
    "            metrics['symmetry_ratio'] = entropy / max_entropy if max_entropy > 0 else 0.0\n",
    "        except:\n",
    "            metrics['symmetry_ratio'] = 0.0\n",
    "\n",
    "        try:\n",
    "            adj_eigenvalues = np.real(nx.adjacency_spectrum(G))\n",
    "            unique_eigenvalues = len(np.unique(np.round(adj_eigenvalues, 10)))\n",
    "            diameter = nx.diameter(G)\n",
    "            metrics['symmetry_ratio_spectral'] = unique_eigenvalues / (diameter + 1)\n",
    "        except:\n",
    "            metrics['symmetry_ratio_spectral'] = 0.0\n",
    "\n",
    "        try:\n",
    "            adj_matrix = nx.adjacency_matrix(self.weighted_graph, weight='weight').todense()\n",
    "            eigenvalues = np.linalg.eigvals(adj_matrix)\n",
    "            metrics['weighted_spectral_radius'] = float(np.max(np.abs(eigenvalues)).real)\n",
    "        except:\n",
    "            metrics['weighted_spectral_radius'] = 0.0\n",
    "\n",
    "        try:\n",
    "            metrics['avg_global_efficiency'] = nx.global_efficiency(G)\n",
    "        except:\n",
    "            metrics['avg_global_efficiency'] = 0.0\n",
    "\n",
    "        try:\n",
    "            metrics['local_efficiency'] = nx.local_efficiency(self.graph)\n",
    "        except:\n",
    "            metrics['local_efficiency'] = 0.0\n",
    "\n",
    "        try:\n",
    "            metrics['average_shortest_path_length'] = nx.average_shortest_path_length(G)\n",
    "        except:\n",
    "            metrics['average_shortest_path_length'] = -1.0\n",
    "\n",
    "        try:\n",
    "            neighbor_degrees = nx.average_neighbor_degree(self.graph)\n",
    "            metrics['mean_degree_neighborhood_avg'] = np.mean(list(neighbor_degrees.values()))\n",
    "            metrics['mean_degree_neighborhood_max'] = np.max(list(neighbor_degrees.values()))\n",
    "        except:\n",
    "            metrics['mean_degree_neighborhood_avg'] = 0.0\n",
    "            metrics['mean_degree_neighborhood_max'] = 0.0\n",
    "\n",
    "        try:\n",
    "            cliques = list(nx.find_cliques(self.graph))\n",
    "            metrics['num_cliques'] = len(cliques)\n",
    "            metrics['max_clique_size'] = max(len(c) for c in cliques) if cliques else 0\n",
    "        except:\n",
    "            metrics['num_cliques'] = 0\n",
    "            metrics['max_clique_size'] = 0\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def extract_node_specific_metrics(self) -> pd.DataFrame:\n",
    "        if nx.is_connected(self.graph):\n",
    "            G = self.graph\n",
    "        else:\n",
    "            largest_cc = max(nx.connected_components(self.graph), key=len)\n",
    "            G = self.graph.subgraph(largest_cc).copy()\n",
    "\n",
    "        try: harmonic_cent = nx.harmonic_centrality(G)\n",
    "        except: harmonic_cent = {n: 0.0 for n in G.nodes()}\n",
    "        try: pagerank = nx.pagerank(G)\n",
    "        except: pagerank = {n: 1.0/G.number_of_nodes() for n in G.nodes()}\n",
    "        try: eig_cent = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "        except: eig_cent = {n: 0.0 for n in G.nodes()}\n",
    "        try: eccentricity = nx.eccentricity(G)\n",
    "        except: eccentricity = {n: -1 for n in G.nodes()}\n",
    "        try: square_clust = nx.square_clustering(self.graph)\n",
    "        except: square_clust = {n: 0.0 for n in self.graph.nodes()}\n",
    "        try: betweenness = nx.betweenness_centrality(G)\n",
    "        except: betweenness = {n: 0.0 for n in G.nodes()}\n",
    "        try: node_clique_num = nx.node_clique_number(self.graph)\n",
    "        except: node_clique_num = {n: 1 for n in self.graph.nodes()}\n",
    "\n",
    "        proximity = {}\n",
    "        try:\n",
    "            for node in G.nodes():\n",
    "                lengths = nx.single_source_shortest_path_length(G, node)\n",
    "                proximity[node] = np.mean(list(lengths.values())) if len(lengths) > 1 else 0.0\n",
    "        except:\n",
    "            proximity = {n: 0.0 for n in G.nodes()}\n",
    "\n",
    "        node_data = []\n",
    "        for node in self.graph.nodes():\n",
    "            node_data.append({\n",
    "                'asn': node,\n",
    "                'degree': self.graph.degree(node),\n",
    "                'harmonic_centrality': harmonic_cent.get(node, 0.0),\n",
    "                'pagerank': pagerank.get(node, 0.0),\n",
    "                'eigenvector_centrality': eig_cent.get(node, 0.0),\n",
    "                'eccentricity': eccentricity.get(node, -1),\n",
    "                'square_clustering': square_clust.get(node, 0.0),\n",
    "                'node_clique_number': node_clique_num.get(node, 1),\n",
    "                'proximity': proximity.get(node, 0.0),\n",
    "                'mediation_centrality': betweenness.get(node, 0.0)\n",
    "            })\n",
    "        return pd.DataFrame(node_data)\n",
    "\n",
    "    def extract_all_features(self, verbose: bool = True) -> Dict:\n",
    "        all_features = {}\n",
    "        if verbose: print(\"Extracting basic metrics...\")\n",
    "        all_features.update(self.extract_basic_metrics())\n",
    "        if verbose: print(\"Extracting centrality metrics...\")\n",
    "        all_features.update(self.extract_centrality_metrics())\n",
    "        if verbose: print(\"Extracting connectivity metrics...\")\n",
    "        all_features.update(self.extract_connectivity_metrics())\n",
    "        if verbose: print(\"Extracting clustering metrics...\")\n",
    "        all_features.update(self.extract_clustering_metrics())\n",
    "        if verbose: print(\"Extracting robustness metrics...\")\n",
    "        all_features.update(self.extract_robustness_metrics())\n",
    "        if verbose: print(\"Extracting advanced metrics...\")\n",
    "        all_features.update(self.extract_advanced_metrics())\n",
    "        if self.label_column is not None:\n",
    "            if verbose: print(\"Extracting label...\")\n",
    "            all_features['label'] = self.extract_label()\n",
    "        return all_features\n",
    "\n",
    "\n",
    "class TimeWindowedFeatureExtractor:\n",
    "    \"\"\"Extract graph features from time-windowed BGP data.\"\"\"\n",
    "\n",
    "    def __init__(self, window_size: str, window_type: str = 'time',\n",
    "                 overlap: float = 0.0, min_updates: int = 10):\n",
    "        self.window_size = window_size\n",
    "        self.window_type = window_type\n",
    "        self.overlap = min(max(overlap, 0.0), 0.9)\n",
    "        self.min_updates = min_updates\n",
    "\n",
    "    def _parse_timestamp(self, df: pd.DataFrame, ts_col: str) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "        if not pd.api.types.is_datetime64_any_dtype(df[ts_col]):\n",
    "            df[ts_col] = pd.to_datetime(df[ts_col], errors='coerce')\n",
    "        df = df.dropna(subset=[ts_col])\n",
    "        return df.sort_values(ts_col).reset_index(drop=True)\n",
    "\n",
    "    def _create_time_windows(self, df, ts_col):\n",
    "        min_time, max_time = df[ts_col].min(), df[ts_col].max()\n",
    "        window_td = pd.Timedelta(self.window_size)\n",
    "        step_td = window_td * (1 - self.overlap)\n",
    "        windows = []\n",
    "        current = min_time\n",
    "        while current < max_time:\n",
    "            windows.append((current, current + window_td))\n",
    "            current += step_td\n",
    "        return windows\n",
    "\n",
    "    def _create_count_windows(self, df):\n",
    "        total = len(df)\n",
    "        wc = int(self.window_size)\n",
    "        step = int(wc * (1 - self.overlap))\n",
    "        windows = []\n",
    "        start = 0\n",
    "        while start < total:\n",
    "            windows.append((start, min(start + wc, total)))\n",
    "            start += step\n",
    "            if total - start < self.min_updates:\n",
    "                break\n",
    "        return windows\n",
    "\n",
    "    def extract_windowed_features(self, df, ts_col, as_path_col, label_col=None, verbose=True):\n",
    "        df = self._parse_timestamp(df, ts_col)\n",
    "        if self.window_type == 'time':\n",
    "            windows = self._create_time_windows(df, ts_col)\n",
    "        else:\n",
    "            windows = self._create_count_windows(df)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Created {len(windows)} windows ({self.window_type}-based, size={self.window_size})\")\n",
    "\n",
    "        all_features = []\n",
    "        for idx, window in enumerate(windows):\n",
    "            if self.window_type == 'time':\n",
    "                start, end = window\n",
    "                window_df = df[(df[ts_col] >= start) & (df[ts_col] < end)]\n",
    "                info = {'window_idx': idx, 'window_start': start, 'window_end': end, 'num_updates': len(window_df)}\n",
    "            else:\n",
    "                s_idx, e_idx = window\n",
    "                window_df = df.iloc[s_idx:e_idx]\n",
    "                info = {'window_idx': idx, 'window_start': window_df[ts_col].min(),\n",
    "                        'window_end': window_df[ts_col].max(), 'num_updates': len(window_df)}\n",
    "\n",
    "            if len(window_df) < self.min_updates:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                extractor = ASGraphFeatureExtractor()\n",
    "                extractor.build_graph_from_dataframe(window_df, as_path_col, label_col, verbose=False)\n",
    "                features = extractor.extract_all_features(verbose=False)\n",
    "                features.update(info)\n",
    "                all_features.append(features)\n",
    "                if verbose and idx % 10 == 0:\n",
    "                    print(f\"  Window {idx}/{len(windows)}: {len(window_df)} updates\")\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"  Window {idx}: Error - {e}\")\n",
    "\n",
    "        result_df = pd.DataFrame(all_features)\n",
    "        info_cols = ['window_idx', 'window_start', 'window_end', 'num_updates']\n",
    "        other_cols = [c for c in result_df.columns if c not in info_cols]\n",
    "        result_df = result_df[info_cols + other_cols]\n",
    "        if verbose:\n",
    "            print(f\"Extracted features for {len(result_df)} windows\")\n",
    "        return result_df\n",
    "\n",
    "\n",
    "print(\"Feature extraction code loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7,746 rows\n",
      "Columns: ['Type', 'Timestamp', 'Subtype', 'Peer_IP', 'Peer_ASN', 'Prefix', 'AS_Path', 'Origin', 'Next_Hop', 'MED', 'Local_Pref', 'Communities', 'Aggregator_Flag', 'Aggregator_ASN Aggregator_IP', 'Label']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Subtype</th>\n",
       "      <th>Peer_IP</th>\n",
       "      <th>Peer_ASN</th>\n",
       "      <th>Prefix</th>\n",
       "      <th>AS_Path</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Next_Hop</th>\n",
       "      <th>MED</th>\n",
       "      <th>Local_Pref</th>\n",
       "      <th>Communities</th>\n",
       "      <th>Aggregator_Flag</th>\n",
       "      <th>Aggregator_ASN Aggregator_IP</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BGP</td>\n",
       "      <td>2025-12-08 17:21:02.824256</td>\n",
       "      <td>ANNOUNCE</td>\n",
       "      <td>10.122.57.238</td>\n",
       "      <td>41336.0</td>\n",
       "      <td>192.0.2.0/24</td>\n",
       "      <td>41336</td>\n",
       "      <td>INCOMPLETE</td>\n",
       "      <td>10.122.57.238</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>65535:65281</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BGP</td>\n",
       "      <td>2025-12-08 17:21:02.837679</td>\n",
       "      <td>ANNOUNCE</td>\n",
       "      <td>10.122.57.238</td>\n",
       "      <td>41336.0</td>\n",
       "      <td>192.0.2.0/24</td>\n",
       "      <td>41336</td>\n",
       "      <td>EGP</td>\n",
       "      <td>10.122.57.238</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>65535:65281</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BGP</td>\n",
       "      <td>2025-12-08 17:21:02.847678</td>\n",
       "      <td>ANNOUNCE</td>\n",
       "      <td>10.122.57.238</td>\n",
       "      <td>41336.0</td>\n",
       "      <td>192.0.2.0/24</td>\n",
       "      <td>41336</td>\n",
       "      <td>IGP</td>\n",
       "      <td>10.122.57.238</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>65535:65281</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BGP</td>\n",
       "      <td>2025-12-08 17:21:02.857748</td>\n",
       "      <td>ANNOUNCE</td>\n",
       "      <td>10.122.57.238</td>\n",
       "      <td>41336.0</td>\n",
       "      <td>203.0.113.0/24</td>\n",
       "      <td>41336</td>\n",
       "      <td>IGP</td>\n",
       "      <td>10.122.57.238</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>65535:65281</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BGP</td>\n",
       "      <td>2025-12-08 17:21:02.857748</td>\n",
       "      <td>ANNOUNCE</td>\n",
       "      <td>10.122.57.238</td>\n",
       "      <td>41336.0</td>\n",
       "      <td>198.51.100.0/24</td>\n",
       "      <td>41336</td>\n",
       "      <td>IGP</td>\n",
       "      <td>10.122.57.238</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>65535:65281</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type                   Timestamp   Subtype        Peer_IP  Peer_ASN  \\\n",
       "0  BGP  2025-12-08 17:21:02.824256  ANNOUNCE  10.122.57.238   41336.0   \n",
       "1  BGP  2025-12-08 17:21:02.837679  ANNOUNCE  10.122.57.238   41336.0   \n",
       "2  BGP  2025-12-08 17:21:02.847678  ANNOUNCE  10.122.57.238   41336.0   \n",
       "3  BGP  2025-12-08 17:21:02.857748  ANNOUNCE  10.122.57.238   41336.0   \n",
       "4  BGP  2025-12-08 17:21:02.857748  ANNOUNCE  10.122.57.238   41336.0   \n",
       "\n",
       "            Prefix AS_Path      Origin       Next_Hop    MED  Local_Pref  \\\n",
       "0     192.0.2.0/24   41336  INCOMPLETE  10.122.57.238  100.0       200.0   \n",
       "1     192.0.2.0/24   41336         EGP  10.122.57.238  100.0       200.0   \n",
       "2     192.0.2.0/24   41336         IGP  10.122.57.238  100.0       200.0   \n",
       "3   203.0.113.0/24   41336         IGP  10.122.57.238  100.0       200.0   \n",
       "4  198.51.100.0/24   41336         IGP  10.122.57.238  100.0       200.0   \n",
       "\n",
       "   Communities  Aggregator_Flag Aggregator_ASN Aggregator_IP   Label  \n",
       "0  65535:65281                0                          NaN  normal  \n",
       "1  65535:65281                0                          NaN  normal  \n",
       "2  65535:65281                0                          NaN  normal  \n",
       "3  65535:65281                0                          NaN  normal  \n",
       "4  65535:65281                0                          NaN  normal  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_CSV_PATH)\n",
    "print(f\"Loaded {len(df):,} rows\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Global Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph constructed: 1491 nodes, 4701 edges\n",
      "\n",
      "Nodes: 1491, Edges: 4701, Density: 0.0042, Connected: True\n",
      "Label: NORMAL\n",
      "Extracting basic metrics...\n",
      "Extracting centrality metrics...\n",
      "Extracting connectivity metrics...\n",
      "Extracting clustering metrics...\n",
      "Extracting robustness metrics...\n",
      "Extracting advanced metrics...\n",
      "Extracting label...\n",
      "\n",
      "Saved to: /home/smotaali/BGP_Traffic_Generation/resultsgraph_features_global.csv\n",
      "Shape: (1, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_nodes</th>\n",
       "      <td>1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_edges</th>\n",
       "      <td>4701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diameter</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_triangles</th>\n",
       "      <td>7729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eigenvector_centrality_avg</th>\n",
       "      <td>0.012543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eigenvector_centrality_max</th>\n",
       "      <td>0.19376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harmonic_centrality_avg</th>\n",
       "      <td>519.673259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harmonic_centrality_max</th>\n",
       "      <td>809.816667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pagerank_avg</th>\n",
       "      <td>0.000671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pagerank_max</th>\n",
       "      <td>0.017419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_centrality_avg</th>\n",
       "      <td>0.004232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>degree_centrality_max</th>\n",
       "      <td>0.122819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>closeness_centrality_avg</th>\n",
       "      <td>0.335503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>closeness_centrality_max</th>\n",
       "      <td>0.50236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>betweenness_centrality_avg</th>\n",
       "      <td>0.00136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>betweenness_centrality_max</th>\n",
       "      <td>0.097564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_centrality_avg</th>\n",
       "      <td>0.00136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_centrality_max</th>\n",
       "      <td>0.096199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eccentricity_avg</th>\n",
       "      <td>7.015426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eccentricity_max</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algebraic_connectivity</th>\n",
       "      <td>0.081002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node_connectivity</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edge_connectivity</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effective_graph_resistance</th>\n",
       "      <td>1003732.833277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural_connectivity</th>\n",
       "      <td>30.339324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>largest_eigenvalue</th>\n",
       "      <td>37.646527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_spectrum_3</th>\n",
       "      <td>2069.157715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_spectrum_4</th>\n",
       "      <td>2687.392905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assortativity</th>\n",
       "      <td>-0.32857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>square_clustering_avg</th>\n",
       "      <td>0.062713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>square_clustering_max</th>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_clustering</th>\n",
       "      <td>0.427389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_components</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>largest_component_size</th>\n",
       "      <td>1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_bridges</th>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_articulation_points</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_spanning_trees</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percolation_threshold</th>\n",
       "      <td>0.017001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percolation_limit</th>\n",
       "      <td>0.982999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_ratio</th>\n",
       "      <td>0.569856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symmetry_ratio_spectral</th>\n",
       "      <td>97.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_spectral_radius</th>\n",
       "      <td>409.166499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_global_efficiency</th>\n",
       "      <td>0.348774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_efficiency</th>\n",
       "      <td>0.48307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_shortest_path_length</th>\n",
       "      <td>3.02466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_degree_neighborhood_avg</th>\n",
       "      <td>77.257966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_degree_neighborhood_max</th>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_cliques</th>\n",
       "      <td>2348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_clique_size</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0\n",
       "num_nodes                               1491\n",
       "num_edges                               4701\n",
       "diameter                                  10\n",
       "num_triangles                           7729\n",
       "eigenvector_centrality_avg          0.012543\n",
       "eigenvector_centrality_max           0.19376\n",
       "harmonic_centrality_avg           519.673259\n",
       "harmonic_centrality_max           809.816667\n",
       "pagerank_avg                        0.000671\n",
       "pagerank_max                        0.017419\n",
       "degree_centrality_avg               0.004232\n",
       "degree_centrality_max               0.122819\n",
       "closeness_centrality_avg            0.335503\n",
       "closeness_centrality_max             0.50236\n",
       "betweenness_centrality_avg           0.00136\n",
       "betweenness_centrality_max          0.097564\n",
       "load_centrality_avg                  0.00136\n",
       "load_centrality_max                 0.096199\n",
       "eccentricity_avg                    7.015426\n",
       "eccentricity_max                          10\n",
       "algebraic_connectivity              0.081002\n",
       "node_connectivity                          1\n",
       "edge_connectivity                          1\n",
       "effective_graph_resistance    1003732.833277\n",
       "natural_connectivity               30.339324\n",
       "largest_eigenvalue                 37.646527\n",
       "weighted_spectrum_3              2069.157715\n",
       "weighted_spectrum_4              2687.392905\n",
       "assortativity                       -0.32857\n",
       "square_clustering_avg               0.062713\n",
       "square_clustering_max                    0.5\n",
       "avg_clustering                      0.427389\n",
       "num_components                             1\n",
       "largest_component_size                  1491\n",
       "num_bridges                              119\n",
       "num_articulation_points                   79\n",
       "num_spanning_trees                        -1\n",
       "percolation_threshold               0.017001\n",
       "percolation_limit                   0.982999\n",
       "symmetry_ratio                      0.569856\n",
       "symmetry_ratio_spectral            97.090909\n",
       "weighted_spectral_radius          409.166499\n",
       "avg_global_efficiency               0.348774\n",
       "local_efficiency                     0.48307\n",
       "average_shortest_path_length         3.02466\n",
       "mean_degree_neighborhood_avg       77.257966\n",
       "mean_degree_neighborhood_max           183.0\n",
       "num_cliques                             2348\n",
       "max_clique_size                           22\n",
       "label                                 normal"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build graph and extract global features\n",
    "extractor = ASGraphFeatureExtractor()\n",
    "graph = extractor.build_graph_from_dataframe(df, AS_PATH_COLUMN, LABEL_COLUMN)\n",
    "extractor.print_graph_summary()\n",
    "\n",
    "global_features = extractor.extract_all_features()\n",
    "global_df = pd.DataFrame([global_features])\n",
    "\n",
    "# Save\n",
    "global_df.to_csv(f\"{OUTPUT_DIR}graph_features_global_20251208_172321.csv\", index=False)\n",
    "print(f\"\\nSaved to: {OUTPUT_DIR}graph_features_global.csv\")\n",
    "print(f\"Shape: {global_df.shape}\")\n",
    "global_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Per-Node Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /home/smotaali/BGP_Traffic_Generation/resultsgraph_features_per_node.csv\n",
      "Shape: (1491, 10)\n",
      "\n",
      "Top 10 ASes by degree:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asn</th>\n",
       "      <th>degree</th>\n",
       "      <th>harmonic_centrality</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>eigenvector_centrality</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>square_clustering</th>\n",
       "      <th>node_clique_number</th>\n",
       "      <th>proximity</th>\n",
       "      <th>mediation_centrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>32934</td>\n",
       "      <td>183</td>\n",
       "      <td>809.816667</td>\n",
       "      <td>0.017419</td>\n",
       "      <td>0.187835</td>\n",
       "      <td>6</td>\n",
       "      <td>0.035502</td>\n",
       "      <td>22</td>\n",
       "      <td>1.989269</td>\n",
       "      <td>0.096359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4637</td>\n",
       "      <td>177</td>\n",
       "      <td>807.733333</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>0.193760</td>\n",
       "      <td>6</td>\n",
       "      <td>0.039195</td>\n",
       "      <td>22</td>\n",
       "      <td>1.989940</td>\n",
       "      <td>0.082451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>9304</td>\n",
       "      <td>173</td>\n",
       "      <td>802.483333</td>\n",
       "      <td>0.015999</td>\n",
       "      <td>0.184680</td>\n",
       "      <td>6</td>\n",
       "      <td>0.037147</td>\n",
       "      <td>22</td>\n",
       "      <td>2.004695</td>\n",
       "      <td>0.087699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8928</td>\n",
       "      <td>171</td>\n",
       "      <td>802.566667</td>\n",
       "      <td>0.015614</td>\n",
       "      <td>0.185743</td>\n",
       "      <td>6</td>\n",
       "      <td>0.038254</td>\n",
       "      <td>22</td>\n",
       "      <td>2.002012</td>\n",
       "      <td>0.076650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>15169</td>\n",
       "      <td>167</td>\n",
       "      <td>798.483333</td>\n",
       "      <td>0.015812</td>\n",
       "      <td>0.180154</td>\n",
       "      <td>6</td>\n",
       "      <td>0.037117</td>\n",
       "      <td>22</td>\n",
       "      <td>2.013414</td>\n",
       "      <td>0.084158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>20940</td>\n",
       "      <td>164</td>\n",
       "      <td>799.066667</td>\n",
       "      <td>0.015095</td>\n",
       "      <td>0.180109</td>\n",
       "      <td>6</td>\n",
       "      <td>0.037901</td>\n",
       "      <td>22</td>\n",
       "      <td>2.006707</td>\n",
       "      <td>0.075098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1273</td>\n",
       "      <td>163</td>\n",
       "      <td>795.350000</td>\n",
       "      <td>0.015809</td>\n",
       "      <td>0.156154</td>\n",
       "      <td>6</td>\n",
       "      <td>0.030168</td>\n",
       "      <td>22</td>\n",
       "      <td>2.021462</td>\n",
       "      <td>0.097564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9002</td>\n",
       "      <td>160</td>\n",
       "      <td>796.150000</td>\n",
       "      <td>0.014708</td>\n",
       "      <td>0.177582</td>\n",
       "      <td>6</td>\n",
       "      <td>0.038301</td>\n",
       "      <td>22</td>\n",
       "      <td>2.013414</td>\n",
       "      <td>0.071449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2497</td>\n",
       "      <td>156</td>\n",
       "      <td>794.733333</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>0.175309</td>\n",
       "      <td>6</td>\n",
       "      <td>0.038867</td>\n",
       "      <td>22</td>\n",
       "      <td>2.014085</td>\n",
       "      <td>0.074462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4323</td>\n",
       "      <td>156</td>\n",
       "      <td>793.233333</td>\n",
       "      <td>0.014251</td>\n",
       "      <td>0.173533</td>\n",
       "      <td>6</td>\n",
       "      <td>0.038187</td>\n",
       "      <td>22</td>\n",
       "      <td>2.020121</td>\n",
       "      <td>0.069305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       asn  degree  harmonic_centrality  pagerank  eigenvector_centrality  \\\n",
       "629  32934     183           809.816667  0.017419                0.187835   \n",
       "16    4637     177           807.733333  0.016212                0.193760   \n",
       "31    9304     173           802.483333  0.015999                0.184680   \n",
       "29    8928     171           802.566667  0.015614                0.185743   \n",
       "125  15169     167           798.483333  0.015812                0.180154   \n",
       "294  20940     164           799.066667  0.015095                0.180109   \n",
       "4     1273     163           795.350000  0.015809                0.156154   \n",
       "30    9002     160           796.150000  0.014708                0.177582   \n",
       "6     2497     156           794.733333  0.014462                0.175309   \n",
       "15    4323     156           793.233333  0.014251                0.173533   \n",
       "\n",
       "     eccentricity  square_clustering  node_clique_number  proximity  \\\n",
       "629             6           0.035502                  22   1.989269   \n",
       "16              6           0.039195                  22   1.989940   \n",
       "31              6           0.037147                  22   2.004695   \n",
       "29              6           0.038254                  22   2.002012   \n",
       "125             6           0.037117                  22   2.013414   \n",
       "294             6           0.037901                  22   2.006707   \n",
       "4               6           0.030168                  22   2.021462   \n",
       "30              6           0.038301                  22   2.013414   \n",
       "6               6           0.038867                  22   2.014085   \n",
       "15              6           0.038187                  22   2.020121   \n",
       "\n",
       "     mediation_centrality  \n",
       "629              0.096359  \n",
       "16               0.082451  \n",
       "31               0.087699  \n",
       "29               0.076650  \n",
       "125              0.084158  \n",
       "294              0.075098  \n",
       "4                0.097564  \n",
       "30               0.071449  \n",
       "6                0.074462  \n",
       "15               0.069305  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract per-node features (uses same graph from above)\n",
    "node_df = extractor.extract_node_specific_metrics()\n",
    "\n",
    "# Save\n",
    "node_df.to_csv(f\"{OUTPUT_DIR}graph_features_per_node_20251208_172321.csv\", index=False)\n",
    "print(f\"Saved to: {OUTPUT_DIR}graph_features_per_node.csv\")\n",
    "print(f\"Shape: {node_df.shape}\")\n",
    "print(\"\\nTop 10 ASes by degree:\")\n",
    "node_df.sort_values('degree', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time-Windowed Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 windows (time-based, size=5min)\n",
      "  Window 0/3: 4417 updates\n",
      "Extracted features for 3 windows\n",
      "\n",
      "Saved to: /home/smotaali/BGP_Traffic_Generation/resultsgraph_features_windowed.csv\n",
      "Shape: (3, 54)\n",
      "\n",
      "First 10 windows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_idx</th>\n",
       "      <th>window_start</th>\n",
       "      <th>window_end</th>\n",
       "      <th>num_updates</th>\n",
       "      <th>num_nodes</th>\n",
       "      <th>num_edges</th>\n",
       "      <th>diameter</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2025-12-08 17:21:02.824256</td>\n",
       "      <td>2025-12-08 17:26:02.824256</td>\n",
       "      <td>4417</td>\n",
       "      <td>891</td>\n",
       "      <td>2350</td>\n",
       "      <td>10</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2025-12-08 17:26:02.824256</td>\n",
       "      <td>2025-12-08 17:31:02.824256</td>\n",
       "      <td>3159</td>\n",
       "      <td>954</td>\n",
       "      <td>2560</td>\n",
       "      <td>10</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2025-12-08 17:31:02.824256</td>\n",
       "      <td>2025-12-08 17:36:02.824256</td>\n",
       "      <td>170</td>\n",
       "      <td>106</td>\n",
       "      <td>191</td>\n",
       "      <td>9</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   window_idx               window_start                 window_end  \\\n",
       "0           0 2025-12-08 17:21:02.824256 2025-12-08 17:26:02.824256   \n",
       "1           1 2025-12-08 17:26:02.824256 2025-12-08 17:31:02.824256   \n",
       "2           2 2025-12-08 17:31:02.824256 2025-12-08 17:36:02.824256   \n",
       "\n",
       "   num_updates  num_nodes  num_edges  diameter   label  \n",
       "0         4417        891       2350        10  normal  \n",
       "1         3159        954       2560        10  normal  \n",
       "2          170        106        191         9  normal  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract time-windowed features\n",
    "windowed_extractor = TimeWindowedFeatureExtractor(\n",
    "    window_size=WINDOW_SIZE,\n",
    "    window_type=WINDOW_TYPE,\n",
    "    overlap=WINDOW_OVERLAP,\n",
    "    min_updates=MIN_UPDATES_PER_WINDOW\n",
    ")\n",
    "\n",
    "windowed_df = windowed_extractor.extract_windowed_features(\n",
    "    df, TIMESTAMP_COLUMN, AS_PATH_COLUMN, LABEL_COLUMN, verbose=True\n",
    ")\n",
    "\n",
    "# Save\n",
    "windowed_df.to_csv(f\"{OUTPUT_DIR}graph_features_windowed_20251208_172321.csv\", index=False)\n",
    "print(f\"\\nSaved to: {OUTPUT_DIR}graph_features_windowed.csv\")\n",
    "print(f\"Shape: {windowed_df.shape}\")\n",
    "print(\"\\nFirst 10 windows:\")\n",
    "display_cols = ['window_idx', 'window_start', 'window_end', 'num_updates', 'num_nodes', 'num_edges', 'diameter']\n",
    "if 'label' in windowed_df.columns:\n",
    "    display_cols.append('label')\n",
    "windowed_df[display_cols].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRACTION COMPLETE\n",
      "============================================================\n",
      "Global features:   1 row x 50 features\n",
      "Per-node features: 1491 rows x 10 features\n",
      "Windowed features: 3 rows x 54 features\n",
      "\n",
      "Output files:\n",
      "  - /home/smotaali/BGP_Traffic_Generation/resultsgraph_features_global.csv\n",
      "  - /home/smotaali/BGP_Traffic_Generation/resultsgraph_features_per_node.csv\n",
      "  - /home/smotaali/BGP_Traffic_Generation/resultsgraph_features_windowed.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXTRACTION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Global features:   {global_df.shape[0]} row x {global_df.shape[1]} features\")\n",
    "print(f\"Per-node features: {node_df.shape[0]} rows x {node_df.shape[1]} features\")\n",
    "print(f\"Windowed features: {windowed_df.shape[0]} rows x {windowed_df.shape[1]} features\")\n",
    "print(\"\\nOutput files:\")\n",
    "print(f\"  - {OUTPUT_DIR}graph_features_global.csv\")\n",
    "print(f\"  - {OUTPUT_DIR}graph_features_per_node.csv\")\n",
    "print(f\"  - {OUTPUT_DIR}graph_features_windowed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
